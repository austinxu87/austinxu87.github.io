a<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Austin Xu</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Austin Xu</h1>
        <img src="figures/Xu_Austin_Picture.jpg" alt="picture of me in Florence, Italy">
        <p> PhD Student <br> Georgia Institute of Technology <br> School of Electrical and Computer Engineering</p>
        <p>Email: <a href="mailto:axu77@gatech.edu">axu77@gatech.edu</a></li></p>
        <p><a href="Xu_CV.pdf" download> CV </a> (Updated August 2023) <br>
          <a href="https://scholar.google.com/citations?user=OUw3iQgAAAAJ&hl=en&oi=sra">Google Scholar<br>
          <a href="https://www.linkedin.com/in/austin-xu"> LinkedIn</a>
        </p>

        <p>My pronouns are he/him </p>

        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </header>
      <section>
        <h1>About Me</h1>
        <hr>
        <p> I'm a PhD student at <a href="https://www.ece.gatech.edu">the School of Electrical and Computer Engineering</a> and <a href="https://ml.gatech.edu/"> the Center for Machine Learning</a> at Georgia Tech. I am fortunate to be advised by
          <a href="https://www.mdav.ece.gatech.edu/">Mark Davenport</a> and to be a <a href="https://mlatgt.blog/2021/05/10/the-machine-learning-center-awards-inaugural-mlgt-fellows/">ML@GT Fellow</a>. I graduated with a BSE in Electrical Engineering from the <a href="https://eecs.engin.umich.edu/">
            University of Michigan</a> in May 2019.</p>

        <p> For summer 2023, I was an AI Research Intern at Duolingo, where I worked with <a href="https://wmonroeiv.github.io">Will Monroe</a> on zero/few-shot retrieval and recommendation with large language models.</p>
        <p> From summer and fall 2022, I was an Applied Scientist Intern at Amazon, where I worked with <a href="https://arjunsesh.github.io/">Arjun Seshadri</a>, <a href="https://scholar.google.com/citations?user=I7LbGLUAAAAJ&hl=en">Mariya Vasileva</a>, and <a href="http://www.achaldave.com">Achal Dave</a> on synthetic dataset generation with GANs.</p>

        <p>My research is focuses on studying <b>human data elicitation</b> from both an <b>empirical</b> and <b>theoretical</b> perspective. Specifically, I am interested in <i>how</i> humans should be queried to provide feedback and <i>when</i> we can avoid asking for human feedback.
          As a result, my past work has spanned</p>
        <ul style="margin-top:-10px;">
          <li> <b>Learning from simple relational queries</b>, such as paired comparisons. How much can we learn when interacting with users with very simple queries?
          <li> <b>Querying humans with mathematically rigorous guarantees</b>. Can we leverage tools from the rich field of <i>high-dimensional statistics</i> to develop theoretical guarantees for learning from human feedback?
          <li> <b>Learning <i>without</i> human feedback</b>. When can we avoid querying humans for additional information? What can we learn in these scenarios?
        </ul>

        <p>In my free time, I enjoy cooking (and eating), reading, running, and watching basketball (NBA and college).</p>

        <h1>Selected publications</h1>
        <hr>
        <ul>
          <li><b>A. Xu</b>, M. I. Vasileva, A. Dave, and A. Seshadri, <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_HandsOff_Labeled_Dataset_Generation_With_No_Additional_Human_Annotations_CVPR_2023_paper.pdf"> "HandsOff: Labeled dataset generation with no additional human annotations,"</a>
            in <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </i>, Vancouver, June 2023.  <b>Highlight Award (top 2.5% of submissions, 26% conference
acceptance rate).</b> [<a href="https://arxiv.org/abs/2212.12645">arxiv</a>][<a href="https://austinxu87.github.io/handsoff"]>website</a>] <br>
            Short version in <i>Neural Information Processing Systems (NeurIPS) SyntheticData4ML Workshop</i>, New Orleans, December 2022.
          <li><b>A. Xu</b> and M. A. Davenport, <a href="https://papers.nips.cc/paper/2020/file/0561bc7ecba98e39ca7994f93311ba23-Paper.pdf">"Simultaneous Preference and Metric Learning from Paired Comparisons,"</a>
            in <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, Online, December 2020. <b>Spotlight Presentation (top 4% of submissions, 20% conference acceptance rate).</b> [<a href="https://arxiv.org/abs/2009.02302">arxiv</a>] [<a href="pages/metric_learning.html">website</a>] [<a href="https://slideslive.com/38938004/simultaneous-preference-and-metric-learning-from-paired-comparisons?ref=speaker-45349-latest">talk</a>] [<a href="bib/simultaneous.bib.txt">bibtex</a>]
          <li><b>A. Xu</b>, A. D. McRae, J. Wang, M. A. Davenport, and A. Pananjady, "Parametric adjustment queries: An inverted measurement paradigm for low-rank metric learning," <i>Under review</i>. <br>
            Short version to appear in <i>International Conference on Machine Learning (ICML) Many Facets of Preference Learning Workshop</i>, Hawaii, July 2023.
          <li>N. Nadagouda, <b>A. Xu</b>, and M. A. Davenport, <a href="https://proceedings.mlr.press/v216/nadagouda23a/nadagouda23a.pdf">"Active metric learning and classification using similarity queries,"</a> in <i>Conference on Uncertainty in Artificial Intelligence (UAI)</i>, Pittsburgh, August 2023. (31% conference acceptance rate) [<a href="https://arxiv.org/abs/2202.01953">arxiv</a>]<br>
              Short version in <i>Neural Information Processing Systems (NeurIPS) Workshop on Human in the Loop Learning</i>, New Orleans, December 2022.
          <li>A. D. McRae, <b>A. Xu</b>, J. Jin, N. Nadagouda, N. Ahad, P. Guan, S. Karnik, M. A. Davenport, <a href="https://ieeexplore.ieee.org/abstract/document/9747038">"Delta distancing: A lifting approach to localizing items from user comparisons,"</a> in <i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, May 2022. [<a href="papers/delta_distancing.pdf" download>ungated</a>]
        </ul>

        <h1>Experience</h1>
        <hr>
        <h2>Work Experience</h2>
        <ul>
          <li> AI Research Intern at <b>Duolingo</b> (Summer 2023)</li>
          <li> Applied Scientist Intern at <b>Amazon</b> (Summer, Fall 2022) </li>
          <li> R&D Summer Intern at <b>Sandia National Laboratories</b> (Summer 2018)</li>
          <li> Student Intern at <b>General Motors</b> (Summer 2017)</li>
        </ul>
        <h2>Teaching Experience</h2>
        <ul>
          <li>Spring 2022: Head TA, Statistical Machine Learning (ECE 6254) [<a href="https://mdav.ece.gatech.edu/ece-6254-spring2022/">website</a>]</li>
          <li>Fall 2019/Spring 2020/Summer 2020: TA, Professional and Technical Communications (ECE 3005)</li>
          <li>Fall 2018/Spring 2019: IA, Discrete Mathematics (University of Michigan -- EECS 203)</li>
        </ul>
      </section>

    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
